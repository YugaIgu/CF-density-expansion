{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import symnum\n",
    "import sympy\n",
    "from sympy import symbols, integrate, simplify, pprint\n",
    "import symnum.numpy as snp\n",
    "import simsde\n",
    "import simsde.operators as operators\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, value_and_grad, lax, vmap\n",
    "from jax.lax import scan\n",
    "import matplotlib.pyplot as plt\n",
    "from jax.config import config\n",
    "import mici\n",
    "import time\n",
    "from weight import expansion, matrixexp\n",
    "import csv \n",
    "config.update('jax_enable_x64', True)\n",
    "config.update('jax_platform_name', 'cpu')\n",
    "from scipy.io import loadmat\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = loadmat(\"1554.mat\") \n",
    "raw_data = data_set['rawdata']\n",
    "\n",
    "dt_original = 0.02\n",
    "dt_data = 0.08\n",
    "t_max = 40\n",
    "t_seq_data = np.arange(int(t_max / dt_data) + 1) * dt_data\n",
    "t_seq_original = np.arange(int(t_max / dt_original) + 1) * dt_original\n",
    "\n",
    "num_obs = int(t_max / dt_original +1)\n",
    "y_obs_original = raw_data[:num_obs,1]\n",
    "y_obs_sparse = y_obs_original[::int(dt_data/dt_original)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.plot(t_seq_data, y_obs_sparse, linestyle='None', color='r', marker='+', markersize=2)\n",
    "\n",
    "ax.set_xlabel('Time (ms)')\n",
    "ax.set_ylabel('Amplitude (real data - 1554)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition FHN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drift_func_rough(x, θ):\n",
    "    ε, γ, β, *_= θ\n",
    "    return snp.array([\n",
    "        γ*x[1] - x[0] + β\n",
    "        ]) \n",
    "\n",
    "def drift_func_smooth(x, θ):\n",
    "    ε, *_= θ\n",
    "    return snp.array([\n",
    "        (x[1] - x[1]**3 - x[0]) / ε\n",
    "        ])\n",
    "\n",
    "def diff_coeff_rough(x, θ):\n",
    "    ε, γ, α, σ = θ\n",
    "    return snp.array([[σ]])\n",
    "\n",
    "def drift_func(x, θ):\n",
    "    return snp.concatenate((drift_func_rough(x, θ), drift_func_smooth(x, θ)))\n",
    "\n",
    "def diff_coeff(x, θ):\n",
    "    return snp.concatenate((diff_coeff_rough(x, θ), snp.zeros((dim_x - dim_r, dim_w))), 0)\n",
    "\n",
    "dim_x = 2\n",
    "dim_r = 1\n",
    "dim_w = 1\n",
    "dim_θ = 4 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_param(u):\n",
    "    return jnp.array(\n",
    "        [ \n",
    "            jnp.exp(u[0]), # ε\n",
    "            jnp.exp(u[1]), # γ\n",
    "            jnp.exp(u[2]), # β \n",
    "            jnp.exp(u[3]), # σ\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def generate_x_0(v_0):\n",
    "    return jnp.array(\n",
    "        [\n",
    "            0.1 * v_0[0], # q_0 \n",
    "            0.2 * v_0[1] # p_0 \n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximate transition density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolic_log_density_expansion_weight_generators = {\n",
    "    'DE-J-3': expansion.log_weight_DE_J_3_FHN,\n",
    "    'DE-J-4': expansion.log_weight_DE_J_4_FHN\n",
    "}\n",
    "\n",
    "jax_log_one_step_weight_funcs = {\n",
    "    key: symnum.numpify(dim_x, dim_x, dim_θ, None, numpy_module=jnp)(\n",
    "        symbolic_log_density_weight_generator(drift_func)\n",
    "    )\n",
    "    for key, symbolic_log_density_weight_generator in \n",
    "    symbolic_log_density_expansion_weight_generators.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling Scheme for Diffusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDL scheme \n",
    "def LDL_one_step_FHN(drift_func):\n",
    "    \n",
    "    def step_func(x, θ, n, t):\n",
    "        ε, γ, *_ = θ \n",
    "        # Computation of mean and covariance with a simpler notation\n",
    "        V_R, V_S, J_SS = symbols('V_R, V_S, J_SS')\n",
    "        Σ_RR, Σ_RS, Σ_SS = symbols('Σ_RR, Σ_RS, Σ_SS')\n",
    "        Σ_sym = sympy.Matrix(snp.array([[Σ_RR, Σ_RS], [Σ_RS, Σ_SS]]))\n",
    "        chol_Σ = Σ_sym.cholesky(hermitian=False) \n",
    "        J_sym = snp.array([[-1, 0], [-1/ε, J_SS]])  \n",
    "        drift_func_sym = snp.array([V_R, V_S])\n",
    "        μ, Σ = matrixexp.mean_and_covariance(x, θ, t, drift_func_sym, J_sym)\n",
    "        \n",
    "        # Substitution of true mean and covariance function into the simpler notation\n",
    "        drift = snp.array(drift_func(x, θ))\n",
    "        J_drift = operators.diff(drift_func(x, θ), x)\n",
    "        print('J_drift', J_drift)\n",
    "        \n",
    "        μ = μ.subs(\n",
    "            {\n",
    "                drift_func_sym[0]:drift[0], \n",
    "                drift_func_sym[1]:drift[1], \n",
    "                J_sym[1,1]:J_drift[1,1]\n",
    "            })\n",
    "\n",
    "        Σ = Σ.subs(\n",
    "            {\n",
    "                drift_func_sym[0]:drift[0], \n",
    "                drift_func_sym[1]:drift[1], \n",
    "                J_sym[1,1]:J_drift[1,1]\n",
    "            })\n",
    "\n",
    "        chol_Σ = chol_Σ.subs(\n",
    "            {\n",
    "                Σ_sym[0,1]:Σ[0,1], \n",
    "                Σ_sym[0,0]:Σ[0,0], \n",
    "                Σ_sym[1,1]:Σ[1,1] \n",
    "            })\n",
    "        \n",
    "        return x + μ + chol_Σ @ n \n",
    "\n",
    "    return step_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generate_x_seq_function(step_func):\n",
    "\n",
    "    @jit\n",
    "    def generate_x_seq(x_0, θ, n_seq, t_seq):\n",
    "        \n",
    "        def compute_next_state(x, n_dt):\n",
    "            n, dt = n_dt\n",
    "            x_next = step_func(x, θ, n, dt)\n",
    "            return x_next, x_next\n",
    "        \n",
    "        _, x_seq = scan(compute_next_state, x_0, (n_seq, t_seq[1:] - t_seq[:-1]))\n",
    "        \n",
    "        return jnp.concatenate((x_0[None], x_seq))\n",
    "        \n",
    "    return generate_x_seq \n",
    "\n",
    "step_funcs_and_dim_n = {\n",
    "    \"local_gaussian\": (\n",
    "        simsde.integrators.hypoelliptic_local_gaussian_step(drift_func_rough, drift_func_smooth, diff_coeff_rough),\n",
    "        2 * dim_w\n",
    "    ),\n",
    "    \"LDL\": (\n",
    "        LDL_one_step_FHN(drift_func),\n",
    "        dim_x\n",
    "    )\n",
    "} \n",
    "\n",
    "generate_x_seq_functions = {\n",
    "    key: get_generate_x_seq_function(\n",
    "        symnum.numpify(dim_x, dim_θ, dim_n, (), numpy_module=jnp)(step_func)\n",
    "    ) \n",
    "    for key, (step_func, dim_n) in step_funcs_and_dim_n.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of LDL sampling scheme (comparision with local gaussian scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for simulation_method in ['LDL', 'local_gaussian']:\n",
    "    rng_obs = np.random.default_rng(20221106)\n",
    "    x_0_obs = np.array([0.05, -0.1])\n",
    "    θ_obs = np.array([3, 6.4, 0.1, 0.7])\n",
    "    \n",
    "    t_max = 40\n",
    "    dt_eg = 0.08\n",
    "    t_seq = np.arange(int(t_max / dt_eg) + 1) * dt_eg \n",
    "    n_seq_obs = rng_obs.standard_normal(\n",
    "        (t_seq.shape[0] - 1, step_funcs_and_dim_n[simulation_method][1])\n",
    "    )\n",
    "\n",
    "    sampler = generate_x_seq_functions[simulation_method]\n",
    "    x_seq_obs = sampler(\n",
    "        x_0_obs, \n",
    "        θ_obs, \n",
    "        n_seq_obs,\n",
    "        t_seq\n",
    "    )\n",
    "\n",
    "    print(simulation_method)\n",
    "    fig, axes = plt.subplots(dim_x, 1, sharex=True, figsize=(12, 4))\n",
    "    labels = 'pq'\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.plot(t_seq, x_seq_obs[:, i], color=f'C{i}')\n",
    "        ax.set_ylabel(labels[i])\n",
    "    axes[-1].set_xlabel('Time')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_u = 4\n",
    "dim_v_0 = 2\n",
    "dim_σ_0 = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to compute log posterior density function and its gradient for inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posterior_density_functions(\n",
    "    generate_param,\n",
    "    generate_x_0,\n",
    "    generate_x_seq,\n",
    "    t_seq, \n",
    "    dim_u, \n",
    "    dim_v_0, \n",
    "    obs_noise_std, \n",
    "    obs_time_indices,\n",
    "    y_obs\n",
    "    ):\n",
    "\n",
    "    dim_z = dim_u + dim_v_0  \n",
    "\n",
    "    @jit \n",
    "    def neg_log_posterior_density(q):\n",
    "        u, v_0, n = q[:dim_u], q[dim_u:dim_z], q[dim_z:]\n",
    "        n_seq = n.reshape((t_seq.shape[0] - 1, -1))\n",
    "        θ = generate_param(u)\n",
    "        x_0 = generate_x_0(v_0)\n",
    "        x_seq = generate_x_seq(x_0, θ, n_seq, t_seq)\n",
    "        # x_seq_at_obs = x_seq[obs_time_indices]\n",
    "        smooth_state = (x_seq[obs_time_indices])[:,1]\n",
    "    \n",
    "        return (\n",
    "            (((y_obs - smooth_state) / obs_noise_std)**2).sum()/2\n",
    "            + (q**2).sum()/2\n",
    "        ) \n",
    "    \n",
    "    @jit \n",
    "    def grad_neg_log_posterior_density(q):\n",
    "        val, grad = value_and_grad(neg_log_posterior_density)(q)\n",
    "        return grad, val\n",
    "\n",
    "    return {\n",
    "        \"neg_log_dens\": lambda q: np.asarray(neg_log_posterior_density(q)), \n",
    "        \"grad_neg_log_dens\": lambda q: tuple(\n",
    "            np.asarray(v) for v in grad_neg_log_posterior_density(q)\n",
    "        )\n",
    "    } \n",
    "\n",
    "\n",
    "def get_posterior_density_functions_with_weight(\n",
    "    generate_param,\n",
    "    generate_x_0,\n",
    "    generate_x_seq,\n",
    "    log_weight_function,  \n",
    "    t_seq, \n",
    "    dim_u, \n",
    "    dim_v_0, \n",
    "    obs_noise_std, \n",
    "    obs_time_indices,\n",
    "    y_obs\n",
    "    ):\n",
    "\n",
    "    dim_z = dim_u + dim_v_0  \n",
    "\n",
    "    @jit\n",
    "    def log_weight_function_θ(θ, x_seq):\n",
    "        log_weight_function_terms = vmap(log_weight_function, (0, 0, None, 0))(\n",
    "            x_seq[1:], x_seq[:-1], θ, t_seq[1:] - t_seq[:-1]\n",
    "        )\n",
    "        return log_weight_function_terms.sum()\n",
    "\n",
    "    @jit \n",
    "    def neg_log_posterior_density(q):\n",
    "        u, v_0, n = q[:dim_u], q[dim_u:dim_z], q[dim_z:]\n",
    "        n_seq = n.reshape((t_seq.shape[0] - 1, -1))\n",
    "        θ = generate_param(u)\n",
    "        x_0 = generate_x_0(v_0)\n",
    "        x_seq = generate_x_seq(x_0, θ, n_seq, t_seq)\n",
    "        # x_seq_at_obs = x_seq[obs_time_indices]\n",
    "        smooth_state = (x_seq[obs_time_indices])[:,1]\n",
    "    \n",
    "        return (\n",
    "            (((y_obs - smooth_state) / obs_noise_std)**2).sum()/2\n",
    "            - log_weight_function_θ(θ, x_seq) \n",
    "            + (q**2).sum()/2\n",
    "        ) \n",
    "    \n",
    "    @jit \n",
    "    def grad_neg_log_posterior_density(q):\n",
    "        val, grad = value_and_grad(neg_log_posterior_density)(q)\n",
    "        return grad, val\n",
    "\n",
    "    return {\n",
    "        \"neg_log_dens\": lambda q: np.asarray(neg_log_posterior_density(q)), \n",
    "        \"grad_neg_log_dens\": lambda q: tuple(\n",
    "            np.asarray(v) for v in grad_neg_log_posterior_density(q)\n",
    "        )\n",
    "    } \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chain = 2\n",
    "obs_noise_std = 0.01\n",
    "dt_obs = dt_data\n",
    "n_warm_up_iter =4000\n",
    "n_main_iter = 4000\n",
    "\n",
    "traces = {}\n",
    "\n",
    "common_kwargs = {\n",
    "    \"generate_param\": generate_param,\n",
    "    \"generate_x_0\": generate_x_0,\n",
    "    \"dim_u\": dim_u,\n",
    "    \"dim_v_0\": dim_v_0,\n",
    "    \"obs_noise_std\": obs_noise_std,\n",
    "    \"y_obs\": y_obs_sparse\n",
    "}\n",
    "\n",
    "# method, dt, color = (\"local_gaussian\", dt, \"C0\")\n",
    "\n",
    "for method, dt in [\n",
    "    (\"MLDL\", dt_data),\n",
    "    (\"DE-J-3\", dt_data),\n",
    "    (\"DE-J-4\", dt_data),\n",
    "]:\n",
    "    print(f\"method={method}, dt_sim={dt}\")\n",
    "\n",
    "    t_seq_inference = np.arange(int(t_max / dt) + 1) * dt\n",
    "    generate_x_seq=generate_x_seq_functions['LDL']\n",
    "    slice_indices = slice(0, None, int(dt_obs / dt))\n",
    "\n",
    "    if method==\"MLDL\": \n",
    "        posterior_density_functions = get_posterior_density_functions(\n",
    "            generate_x_seq = generate_x_seq,\n",
    "            t_seq = t_seq_inference,  \n",
    "            obs_time_indices = slice_indices,\n",
    "            **common_kwargs\n",
    "        )\n",
    "    else: \n",
    "        posterior_density_functions = get_posterior_density_functions_with_weight(\n",
    "                generate_x_seq = generate_x_seq,\n",
    "                t_seq = t_seq_inference,  \n",
    "                obs_time_indices = slice_indices,\n",
    "                log_weight_function = jax_log_one_step_weight_funcs[method],  \n",
    "                **common_kwargs\n",
    "            )\n",
    "\n",
    "    def trace_func(state):\n",
    "        θ = generate_param(state.pos[:dim_u])\n",
    "        x_0 = generate_x_0(state.pos[dim_u:dim_u+dim_v_0])\n",
    "        n_seq = state.pos[dim_v_0 + dim_u:].reshape((t_seq_inference.shape[0] - 1, -1))\n",
    "        x_seq = generate_x_seq(x_0, θ, n_seq, t_seq_inference)\n",
    "        return {\"ε\": θ[0], \"α\": θ[1], \"β\": θ[2], \"σ\": θ[3], \"x_seq\": x_seq} \n",
    "\n",
    "    dim_q = (\n",
    "        common_kwargs[\"dim_u\"] \n",
    "        + common_kwargs[\"dim_v_0\"]\n",
    "        + step_funcs_and_dim_n['LDL'][1] * (len(t_seq_inference) - 1)\n",
    "    )\n",
    "\n",
    "    rng = np.random.default_rng(20241106)\n",
    "    system = mici.systems.EuclideanMetricSystem(**posterior_density_functions)\n",
    "    integrator = mici.integrators.LeapfrogIntegrator(system)\n",
    "    sampler = mici.samplers.DynamicMultinomialHMC(system, integrator, rng)\n",
    "    adapters = [mici.adapters.DualAveragingStepSizeAdapter(0.8)]\n",
    "    init_states = []\n",
    "\n",
    "    while len(init_states) < n_chain:\n",
    "        q = rng.standard_normal(dim_q)\n",
    "        g, v = system._grad_neg_log_dens(q)\n",
    "        if not (np.any(np.isnan(g)) or np.isnan(v)):\n",
    "            init_states.append(q)\n",
    "\n",
    "    start = time.time() \n",
    "    final_states, traces[method, dt], stats = sampler.sample_chains(\n",
    "        n_warm_up_iter=n_warm_up_iter,\n",
    "        n_main_iter=n_main_iter,\n",
    "        init_states=init_states,\n",
    "        monitor_stats=[\"n_step\", \"accept_stat\"],\n",
    "        trace_funcs=[trace_func],\n",
    "        adapters=adapters,\n",
    "        # n_process=1,\n",
    "    )\n",
    "    end = time.time()\n",
    "    print(f'Computation time: {end-start} s')\n",
    "\n",
    "    with open(f'FHN-mcmc-NCP-{method}-T={t_max}-dt={dt}-warmup={n_warm_up_iter}-mainiter={n_main_iter}.csv', \"w\") as f:\n",
    "        csv_w = csv.writer(f, lineterminator='\\n')\n",
    "        for index in ['ε', 'α', 'β', 'σ']:\n",
    "            csv_w.writerows(traces[method, dt].get(index))\n",
    "  \n",
    "    x_seq = traces[method, dt].get('x_seq')\n",
    "    for c in range(n_chain):\n",
    "        with open(f'FHN-mcmc-smooth-{method}-T={t_max}-dt={dt}-warmup={n_warm_up_iter}-mainiter={n_main_iter}-chain{c+1}-noise={obs_noise_std}.csv', \"w\", newline=\"\") as f:\n",
    "            w = csv.writer(f, delimiter=\",\")\n",
    "            for data_list in x_seq[c][:,:,1]:\n",
    "                w.writerow(data_list)# print(p_seq) \n",
    "\n",
    "    for c in range(n_chain):\n",
    "        with open(f'FHN-mcmc-rough-{method}-T={t_max}-dt={dt}-warmup={n_warm_up_iter}-mainiter={n_main_iter}-chain{c+1}-noise={obs_noise_std}.csv', \"w\", newline=\"\") as f:\n",
    "            w = csv.writer(f, delimiter=\",\")\n",
    "            for data_list in x_seq[c][:,:,0]:\n",
    "                w.writerow(data_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_seq_obs = np.arange(int(t_max / dt_obs) + 1) * dt_obs\n",
    "\n",
    "for method, dt in [\n",
    "    (\"MLDL\", dt_data),\n",
    "    (\"DE-J-3\", dt_data),\n",
    "    (\"DE-J-4\", dt_data),\n",
    "]:\n",
    "    t_seq_sim = np.arange(int(t_max / dt) + 1) * dt\n",
    "\n",
    "    for c in range(n_chain):\n",
    "        fig, ax = plt.subplots(sharex=True, figsize=(9, 3), dpi=400)\n",
    "        for i in range(n_main_iter):\n",
    "            q_seq = traces[method, dt].get('x_seq')[c][i,:,1]\n",
    "            ax.plot(t_seq_sim, q_seq, color='C0', alpha=0.1)\n",
    "            ax.plot(t_seq_obs, y_obs_sparse, 'r', alpha=0.1)\n",
    "            ax.set_xlabel('Time (ms)')\n",
    "            ax.set_ylabel('Smooth')\n",
    "        \n",
    "        fig.savefig(f\"Smooth_T={t_max}-dt={dt}-warmup={n_warm_up_iter}-mainiter={n_main_iter}-chain{c+1}-noise={obs_noise_std}.png\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    for c in range(n_chain):\n",
    "        fig, ax = plt.subplots(sharex=True, figsize=(9, 3), dpi=400)\n",
    "        for i in range(n_main_iter):\n",
    "            p_seq = traces[method, dt].get('x_seq')[c][i,:,0]\n",
    "            ax.plot(t_seq_sim, p_seq, color='C0', alpha=0.1)\n",
    "            ax.set_xlabel('Time (ms)')\n",
    "            ax.set_ylabel('Rough')\n",
    "        \n",
    "        fig.savefig(f\"Rough_T={t_max}-dt={dt}-warmup={n_warm_up_iter}-mainiter={n_main_iter}-chain{c+1}-noise={obs_noise_std}.png\")\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    x_seq = traces[method, dt].get('x_seq')\n",
    "\n",
    "    for c in range(n_chain):\n",
    "        with open(f'FHN-mcmc-smooth-T={t_max}-dt={dt}-warmup={n_warm_up_iter}-mainiter={n_main_iter}-chain{c+1}-noise={obs_noise_std}.csv', \"w\", newline=\"\") as f:\n",
    "            w = csv.writer(f, delimiter=\",\")\n",
    "            for data_list in x_seq[c][:,:,1]:\n",
    "                w.writerow(data_list)# print(p_seq) \n",
    "\n",
    "    for c in range(n_chain):\n",
    "        with open(f'FHN-mcmc-rough-T={t_max}-dt={dt}-warmup={n_warm_up_iter}-mainiter={n_main_iter}-chain{c+1}-noise={obs_noise_std}.csv', \"w\", newline=\"\") as f:\n",
    "            w = csv.writer(f, delimiter=\",\")\n",
    "            for data_list in x_seq[c][:,:,0]:\n",
    "                w.writerow(data_list)# print(p_seq) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
